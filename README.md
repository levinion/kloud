# kloud
a sync cloud storage

同步用云盘 kloud

基于消息的云端同步。对于每个云端存储，在每台设备上存在一个本地文件映射。每次对本地文件的修改都会同步到云端，并由云端将修改行为推送到其他设备，从而保证所有设备的同步。

1. 服务端

服务端的工作主要包括：消息的监听和推送，帐号和设备管理，文件操作，版本管理，文件备份。

2. 客户端

客户端的工作是用户设备登录，以及一些配置项，其主要功能通过守护程序实现。

Q:

1. 同步问题

理想的同步方式是增量同步，只同步修改部分的内容。通常使用的方式是对文件做分块，通过哈希摘要算法判断该块是否修改，若修改则更新这部分的内容。

哈希的问题在于弱哈希碰撞概率高，而强哈希计算量大性能要求高。因此一般先比对弱哈希，若一致才去计算强哈希；强哈希一致则认为该块内容没有变化。

2. 数据结构

一个文件的数据结构应该包括以下部分：

- 文件信息，主要是文件名和版本
- 摘要哈希值的索引列表：file: [block1,block2,block3,block4,...]；每个块都默认计算弱哈希和保存它的引用者（文件），不存在引用者则删除。
- block: strcut{weak_hash, belong}, get_strong_hash
- 每块索引对应的内容：map[hash]content，为保证内容一致性，这里应当使用强哈希

所有内容使用一个kv数据库存储（这部分可以照搬为了botland设计的db库）

3. 流程

- 一个文件被修改（监听机制，这部分可以通过操作系统api，或封装过的fsnotify包实现）
- 从头开始分块，并按照索引列表比对每个块的哈希，若相同则不更改，否则增加新的块，并更新索引


4. 注意

- 计算量应当主要放在客户端，由客户端直接发起对数据库的修改操作，从而尽可能地减少服务器压力
- 单纯按照一定比特分块对比很难应对文件头部被修改的问题，因为这种方式很可能导致后面的块哈希都无法对应，从而导致几乎要更新整个文件的情况。因此一种比较好的方式是按照特殊字符，比如换行符进行分块，如果块哈希不匹配，则新增块并在原索引前插入索引，继续对比下个块和原索引；当遇到文件尾，此时还存在未对比的块，则删除这部分块的索引。这种方式的缺点在于对一些特殊的二进制大文件很难起到好的效果，而只适合那些适合人阅读的文件格式，因此可能需要对二进制大文件进行特殊操作。

5. 清理

如果只是新增块而不是删除块服务器容量很快就会不够，因此需要清理机制。

1. 定时任务，遍历所有文件，包括备份，如不存在对应块的索引则清除。缺点是服务器计算量较大。
2. 限制备份数量，当有新备份时清除老的备份。通过时间和使用频率计算权重。
3. 如上面所说，建立块引用者机制，无引用者时删除。